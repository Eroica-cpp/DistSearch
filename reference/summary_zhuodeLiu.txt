今天看的东西的summary:
目前的Hadoop与Lucene的结合方法都是这样的:
由于Lucene需要随机读/写索引,而Hadoop只支持随机读,不支持随机写,只能顺序写, 所以要使用Hadoop,需要一些折衷的方法.

①contrib/index: 这个是Hadoop自己提供的方法. 这个方法中, 因为hdfs只支持序列化的写所以索引文件无法被直接存在hdfs上，所以会被存在lucene的本地目录上。这个方法先在本地建一个tmpdir,把索引写在上面,然后再上传到hadoop上的perm dir,删除tmpdir.hadoop提供的这个和lucene结合的实质，是将索引写到本地文件，再传到hdfs上。在这个方法下,MapReduce的只是用作建立索引的过程,而不是搜索过程.
②Nut: 索引不放在HDFS上了,索引放在一个名叫"索引服务器"或"搜索服务器"的地方(可以是一个集群).另外,使用Hadoop Mapper/Reducer 建立索引。再将索引从HDFS分发到各个索引服务器。
③solr: 使用"SolrCloud"项目来提供实现分布式特性. 也是就是用SolrCould来管理这些分布式的索引数据和进行分布式的搜索.简单地说,Solr与MapReduce无关.
However,
Solr has support for writing and reading its index and transaction log files to the HDFS distributed filesystem. This does not use Hadoop Map-Reduce to process Solr data, rather it only uses the HDFS filesystem for index and transaction log file storage.
来自 <https://cwiki.apache.org/confluence/display/solr/Running+Solr+on+HDFS?focusedCommentId=33297067#comment-33297067>

不过我目前还不能确定: 
solrcloud是不是已经包含了一个分布式文件系统, 不需要我们把solr放到hdfs上就能够实现分布式特性了. 
如果你有空的话,麻烦帮我看一下"How SolrCloud Works" https://cwiki.apache.org/confluence/display/solr/How+SolrCloud+Works